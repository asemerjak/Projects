{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przetwarzanie wstępne. Filtracja kontekstowa.\n",
    "\n",
    "\n",
    "### Cel:\n",
    "- zapoznanie z pojęciem kontekstu / filtracji kontekstowej,\n",
    "- zapoznanie z pojęciem konwolucji (splotu),\n",
    "- zapoznanie z wybranymi filtrami:\n",
    "\t- filtry liniowe dolnoprzepustowe:\n",
    "\t\t- filtr uśredniający,\n",
    "\t\t- filtr Gaussa.\n",
    "\t- filtry nielinowe:\n",
    "\t\t- mediana,\n",
    "\t\t- mediana dla obrazów kolorowych.\n",
    "\t- filtry liniowe górnoprzepustowe:\n",
    "\t\t\t- laplasjan,\n",
    "\t\t\t- operator Robersta, Prewitta, Sobela.\n",
    "- zadanie domowe: adaptacyjna filtracja medianowa.\n",
    "\n",
    "### Filtry liniowe uśredniające (dolnoprzepustowe)\n",
    "\n",
    "Jest to podstawowa rodzina filtrów stosowana w cyfrowym przetwarzaniu obrazów. \n",
    "Wykorzystuje się je w celu \"rozmazania\" obrazu i tym samym redukcji szumów (zakłóceń) na obrazie.\n",
    "Filtr określony jest przez dwa parametry: rozmiar maski (ang. _kernel_) oraz wartości współczynników maski.\n",
    "\n",
    "Warto zwrócić uwagę, że omawiane w niniejszym rozdziale operacje generują nową wartość piksela na podstawie pewnego fragmentu obrazu (tj. kontekstu), a nie jak operacje punktowe tylko na podstawie jednego piksela.\n",
    "\n",
    "\n",
    "1. Wczytaj obraz _plansza.png_.\n",
    "W dalszej części ćwiczenia sprawdzenie działania filtracji dla innych obrazów sprowadzi się do wczytania innego pliku.\n",
    "\n",
    "2. Podstawowa funkcja to `cv2.filter2D`  - realizacja filtracji konwolucyjnej.\n",
    "   Proszę sprawdzić jej dokumentację i zwrócić uwagę na obsługę problemu brzegowego (na krawędziach istnieją piksele dla których nie da się wyznaczyć otoczenia).\n",
    "\n",
    "  Uwaga. Problem ten można też rozwiązać z użyciem funkcji `signal.convolve2d` z biblioteki _scipy_ (`from scipy import signal`).\n",
    "\n",
    "3. Stwórz podstawowy filtr uśredniający o rozmiarze $3 \\times 3$ -- za pomocą funkcji `np.ones`. Wykonaj konwolucję na wczytanym obrazie. Na wspólnym rysunku wyświetl obraz oryginalny, po filtracji oraz moduł z różnicy.\n",
    "\n",
    "4. Przeanalizuj otrzymane wyniki. Jakie elementy zawiera obraz \"moduł z różnicy\"? Co na tej podstawie można powiedzieć o filtracji dolnoprzepustowej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "# Obrazki\n",
    "if not os.path.exists(\"jet.png\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/06_Context/jet.png --no-check-certificate\n",
    "if not os.path.exists(\"kw.png\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/06_Context/kw.png --no-check-certificate\n",
    "if not os.path.exists(\"moon.png\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/06_Context/moon.png --no-check-certificate\n",
    "if not os.path.exists(\"lenaSzum.png\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/06_Context/lenaSzum.png --no-check-certificate\n",
    "if not os.path.exists(\"lena.png\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/06_Context/lena.png --no-check-certificate\n",
    "if not os.path.exists(\"plansza.png\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/06_Context/plansza.png --no-check-certificate\n",
    "\n",
    "\n",
    "jet = cv2.imread('jet.png', cv2.IMREAD_GRAYSCALE)\n",
    "kw = cv2.imread('kw.png', cv2.IMREAD_GRAYSCALE)\n",
    "moon = cv2.imread('moon.png', cv2.IMREAD_GRAYSCALE)\n",
    "lenasz = cv2.imread('lenaSzum.png', cv2.IMREAD_GRAYSCALE)\n",
    "lena = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)\n",
    "plansza = cv2.imread('plansza.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones(shape = (3, 3)) * (1/9)\n",
    "plansza_filter2D = cv2.filter2D(plansza, -1, kernel)\n",
    "plansza_convolved2d = signal.convolve2d(plansza, kernel, mode='same')\n",
    "\n",
    "def disp_img_and_filtered(img, filtered):\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(24, 8)\n",
    "    ax[0].imshow(img, 'gray', vmin=0, vmax=256)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Obraz oryginalny\")\n",
    "\n",
    "    ax[1].imshow(filtered, 'gray', vmin=0, vmax=256)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Obraz przefiltrowany\")\n",
    "    \n",
    "    mod = np.abs(img - filtered)\n",
    "    ax[2].imshow(mod, 'gray', vmin=0, vmax=256)\n",
    "    ax[2].axis(\"off\")\n",
    "    ax[2].set_title(\"Moduł z różnicy\")\n",
    "\n",
    "disp_img_and_filtered(plansza, plansza_filter2D)\n",
    "disp_img_and_filtered(plansza, plansza_convolved2d)"
   ]
  },
  {
   "source": [
    "Analizując przefiltrowany obraz cieżko jest gołym okiem zauważyć różnicę pomiędzy działaniem funkcji filter2D, a convolve2d (poza obecnością bardzo wąskiej ramki dla drugiej funkcji). Inaczej się ma sprawa z modułem z różnicy - tutaj dla pierwszej funkcji widzimy wyraźne kontury każdego elementu, natomiast dla convolve2d są one zależne od koloru elementu (mogą być bardziej lub mniej wyraźne). Warto też zwrócić uwagę na różnicę w szumach na module z różnicy - w pierwszym obrazie szum jest rozmyty, nayomiast w drugim - dosyć wyraźny."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Na wspólnym rysunku wyświetl wyniki filtracji uśredniającej z oknem o rozmiarze 3, 5, 9, 15 i 35. \n",
    "Wykorzystaj polecenie `plt.subplot`. \n",
    "Przeanalizuj wpływ rozmiaru maski na wynik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_different_sizes(img):\n",
    "    fig, ax = plt.subplots(1, 6)\n",
    "    fig.set_size_inches(24, 4)\n",
    "    i = 1\n",
    "    ax[0].imshow(img, 'gray', vmin=0, vmax=256)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Obraz oryginalny\")\n",
    "    for size in [3, 5, 9, 15, 35]:\n",
    "        kernel = np.ones(shape = (size, size)) / (size**2)\n",
    "        img_filt = cv2.filter2D(img, -1, kernel)\n",
    "        ax[i].imshow(img_filt, 'gray', vmin=0, vmax=256)\n",
    "        ax[i].axis(\"off\")\n",
    "        ax[i].set_title(\"Rozmiar maski = \" + str(size))\n",
    "        i += 1\n",
    "\n",
    "disp_different_sizes(plansza)"
   ]
  },
  {
   "source": [
    "Zwiększanie rozmiaru maski powoduje zwiększenie rozmycia obrazu."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Wczytaj obraz _lena.png_.\n",
    "Zaobserwuj efekty filtracji dolnoprzepustowej dla obrazu rzeczywistego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_different_sizes(lena)"
   ]
  },
  {
   "source": [
    "Zgodnie z oczekiwaniami obraz przefiltrowany staje się bardziej rozmyty. Dla rozmiaru większego niż 5 rozmycie zaburza widoczność detali."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Niekorzystny efekt towarzyszący wykonanym filtracjom dolnoprzepustowym to utrata ostrości. \n",
    "Częściowo można go zniwelować poprzez odpowiedni dobór maski. \n",
    "Wykorzystaj maskę:  `M = np.array([1 2 1; 2 4 2; 1 2 1])`. \n",
    "Przed obliczeniami należy jeszcze wykonać normalizację - podzielić każdy element maski przez sumę wszystkich elementów: `M = M/sum(sum(M));`.\n",
    "Tak przygotowaną maskę wykorzystaj w konwolucji - wyświetl wyniki tak jak wcześniej.\n",
    "Możliwe jest też wykorzystywanie innych masek - współczynniki można dopasowywać do konkretnego problemu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "M = M/sum(sum(M))\n",
    "\n",
    "lena_convolved2d = signal.convolve2d(lena, M, mode='same')\n",
    "\n",
    "def disp_img_and_filt(img, filtered):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(16, 8)\n",
    "    ax[0].imshow(img, 'gray', vmin=0, vmax=256)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Obraz oryginalny\")\n",
    "\n",
    "    ax[1].imshow(filtered, 'gray', vmin=0, vmax=256)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Obraz przefiltrowany\")\n",
    "\n",
    "disp_img_and_filt(lena, lena_convolved2d)"
   ]
  },
  {
   "source": [
    "Obraz został wygładzony bez dużej strat ostrości."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Skuteczną i często wykorzystywaną maską jest tzw. maska Gasussa.\n",
    "Jest to zbiór liczb, które aproksymują dwuwymiarowy rozkład Gaussa. \n",
    "Parametrem jest odchylenie standardowe i rozmiar maski.\n",
    "\n",
    "9. Wykorzystując przygotowaną funkcję `fgaussian` stwórz maskę o rozmiarze $5 \\times 5$ i odchyleniu standardowym 0.5.\n",
    "  Wykorzystując funkcję `mesh` zwizualizuj filtr.\n",
    "  Sprawdź jak parametr ``odchylenie standardowe'' wpływa na ``kształt'' filtru.\n",
    "\n",
    "  Uwaga. W OpenCV dostępna jest *dedykowana* funkcja do filtracji Gaussa - `GaussianBlur`.\n",
    "  Proszę na jednym przykładzie porównać jej działanie z użytym wyżej rozwiązaniem.\n",
    "\n",
    "10. Wykonaj filtrację dla wybranych (2--3) wartości odchylenia standardowego.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fgaussian(size, sigma):\n",
    "     m = n = size\n",
    "     h, k = m//2, n//2\n",
    "     x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "     g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "     return g/g.sum() \n",
    "\n",
    "def mesh(fun, size):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    X = np.arange(-size//2, size//2, 1)\n",
    "    Y = np.arange(-size//2, size//2, 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = fun\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    plt.show()\n",
    "    \n",
    "mask1 = fgaussian(5, 0.1)\n",
    "mask2 = fgaussian(5, 0.5)\n",
    "mask3 = fgaussian(5, 3)\n",
    "mesh(mask1, 5)\n",
    "mesh(mask2, 5)\n",
    "mesh(mask3, 5)\n",
    "\n",
    "lena_1 = signal.convolve2d(lena, mask1, mode='same')\n",
    "lena_2 = signal.convolve2d(lena, mask2, mode='same')\n",
    "lena_3 = signal.convolve2d(lena, mask3, mode='same')\n",
    "lena_gauss_cv = cv2.GaussianBlur(lena, (5,5), 3)\n",
    "disp_img_and_filt(lena, lena_1)\n",
    "disp_img_and_filt(lena, lena_2)\n",
    "disp_img_and_filt(lena, lena_3)\n",
    "disp_img_and_filt(lena, lena_gauss_cv)"
   ]
  },
  {
   "source": [
    "Zwiększanie odchylenia standardowego Zwiększa rozmycie obrazu, a wizualizacja filtru jest mniej 'ostra', wypukłość jest bardziej rozłożona na wszystkie strony, a nie skoncentrowana w środku. Dodatkowo, im większe odchylenie, tym mniejsze są wartości na osi z. Zaimplementowana tutaj funkcja wydaje się dawać takie same eekty, jak wbudowana funkcjia GaussianBlur z pakietu cv2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtry nieliniowe -- mediana\n",
    "\n",
    "Filtry rozmywające redukują szum, ale niekorzystnie wpływają na ostrość obrazu.\n",
    "Dlatego często wykorzystuje się filtry nieliniowe - np. filtr medianowy (dla przypomnienia: mediana - środkowa wartość w posortowanym ciągu liczb).\n",
    "\n",
    "Podstawowa różnica pomiędzy filtrami liniowymi, a nieliniowymi polega na tym, że przy filtracji liniowej na nową wartość piksela ma wpływ wartość wszystkich pikseli z otoczenia (np. uśrednianie, czasem ważone), natomiast w przypadku filtracji nieliniowej jako nowy piksel wybierana jest któraś z wartości otoczenia - według jakiegoś wskaźnika (wartość największa, najmniejsza czy właśnie mediana).\n",
    "\n",
    "\n",
    "1. Wczytaj obraz _lenaSzum.png_ (losowe 10% pikseli białych lub czarnych - tzw. zakłócenia impulsowe). Przeprowadź filtrację uśredniającą z rozmiarem maski 3x3. Wyświetl, podobnie jak wcześniej, oryginał, wynik filtracji i moduł z różnicy. Wykorzystując funkcję ``cv2.medianBlur` wykonaj filtrację medianową _lenaSzum.png_ (z rozmiarem maski $3 \\times 3$). Wyświetl, podobnie jak wcześniej, oryginał, wynik filtracji i moduł z różnicy. Która filtracja lepiej radzi sobie z tego typu szumem?\n",
    "\n",
    "  Uwaga. Taki sam efekt da również użycie funkcji `signal.medfilt2d`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenasz_convolved2d = signal.convolve2d(lenasz, kernel, mode='same')\n",
    "lenasz_medianblurr = cv2.medianBlur(lenasz, 3)\n",
    "disp_img_and_filtered(lenasz, lenasz_convolved2d)\n",
    "disp_img_and_filtered(lenasz, lenasz_medianblurr)"
   ]
  },
  {
   "source": [
    "Filtracja medianowa dała znacznie lepszy rezultat. Moduł z różnicy zawiera także kontury obrazu, a nie tylko sam szum. Pierwszy sposób filtracji złagodził szum (rozmył go), jednak nie został on usunięty."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Przeprowadź filtrację uśredniającą, a następnie medianową obrazu _lena.png_.\n",
    "   Wyniki porównaj - dla obu wyświetl: oryginał, wynik filtracji i moduł z różnicy.\n",
    "   Szczególną uwagę zwróć na ostrość i krawędzie.\n",
    "   W której filtracji krawędzie zostają lepiej zachowane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_convolved2d = signal.convolve2d(lena, kernel, mode='same')\n",
    "lena_medianblurr = cv2.medianBlur(lena, 3)\n",
    "disp_img_and_filtered(lena, lena_convolved2d)\n",
    "disp_img_and_filtered(lena, lena_medianblurr)"
   ]
  },
  {
   "source": [
    "Lepiej zachowane krawędzie i ostrość występują dla drugiej funkcji - korzystającej z mediany."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ciekawy efekt można uzyskać wykonując filtrację medianową wielokrotnie. Określa się go mianem  posteryzacji.  W wyniku przetwarzania z obrazka usunięte zostają detale, a duże obszary uzyskują tą samą wartość jasności.  Wykonaj operację mediany $5 \\times 5$ na obrazie _lena.png_ 10-krotnie. (wykorzystaj np. pętlę `for`).\n",
    "\n",
    "\n",
    "Inne filtry nieliniowe:\n",
    "- filtr modowy - moda (dominanta) zamiast mediany,\n",
    "- filtr olimpijski - średnia z podzbioru otoczenia (bez wartości ekstremalnych),\n",
    "- hybrydowy filtr medianowy - mediana obliczana osobno w różnych podzbiorach otoczenia (np. kształt ``x'',``+''), a jako wynik brana jest mediana ze zbioru wartość elementu centralnego, mediana z ``x'' i mediana z ``+'',\n",
    "- filtr minimalny i maksymalny (będą omówione przy okazji operacji morfologicznych w dalszej części kursu).\n",
    "\n",
    "\n",
    "Warto zdawać sobie sprawę, z szerokich możliwości dopasowywania rodzaju filtracji do konkretnego rozważanego problemu i rodzaju zaszumienia występującego na obrazie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_10 = cv2.medianBlur(lena, 5)\n",
    "for i in range(10):\n",
    "    lena_10 = cv2.medianBlur(lena_10, 5)\n",
    "\n",
    "disp_img_and_filtered(lena, lena_10)"
   ]
  },
  {
   "source": [
    "Obraz został rozmyty w dosyć charakterystyczny sposób, gdyż istotniejsze krawędzie wciąż są wyraźne."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtry liniowe górnoprzepustowe (wyostrzające, wykrywające krawędzie)\n",
    "\n",
    "Zadaniem filtrów górnoprzepustowych jest wydobywanie z obrazu składników odpowiedzialnych za szybkie zmiany jasności - konturów, krawędzi, drobnych elementów tekstury.\n",
    "\n",
    "### Laplasjan (wykorzystanie drugiej pochodnej obrazu)\n",
    "\n",
    "1. Wczytaj obraz _moon.png_.\n",
    "\n",
    "2. Wprowadź podstawową maskę laplasjanu:\n",
    "\\begin{equation}\n",
    "M = \n",
    "\\begin{bmatrix}\n",
    "0 & 1& 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "3. Przed rozpoczęciem obliczeń należy dokonać normalizacji maski - dla rozmiaru $3 \\times 3$ podzielić każdy element przez 9.\n",
    "   Proszę zwrócić uwagę, że nie można tu zastosować takiej samej normalizacji, jak dla filtrów dolnoprzepustowanych, gdyż skutkowałby to dzieleniem przez 0.\n",
    "\n",
    "4. Wykonaj konwolucję obrazu z maską (`c2.filter2D`). Przed wyświetleniem, wynikowy obraz należy poddać normalizacji (występują ujemne wartości). Najczęściej wykonuje się jedną z dwóch operacji:\n",
    "- skalowanie (np. poprzez dodatnie 128 do każdego z pikseli),\n",
    "- moduł (wartość bezwzględna).\n",
    "\n",
    "Wykonaj obie normalizacje. \n",
    "Na wspólnym wykresie wyświetl obraz oryginalny oraz przefiltrowany po obu normalizacjach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_l = np.array([[0, 1/9, 0], [1/9, -4/9, 1/9], [0, 1/9, 0]], dtype=np.float32)\n",
    "moon_1 = np.ones(shape = moon.shape, dtype=np.float32)\n",
    "cv2.filter2D(moon.astype(np.float32), -1, M_l, dst = moon_1)\n",
    "moon_2 = moon_1 + 128\n",
    "moon_3 = np.abs(moon_1)\n",
    "\n",
    "def disp_img_and_filt_no0256(img, filtered):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(16, 8)\n",
    "    ax[0].imshow(img, 'gray', vmin=0, vmax=256)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Obraz oryginalny\")\n",
    "\n",
    "    ax[1].imshow(filtered, 'gray')\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Obraz przefiltrowany\")\n",
    "\n",
    "disp_img_and_filt_no0256(moon, moon_2)\n",
    "disp_img_and_filt_no0256(moon, moon_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Efekt wyostrzenia uzyskuje się po odjęciu/dodaniu (zależy do maski) rezultatu filtracji laplasjanowej i oryginalnego obrazu. Wyświetl na jednym wykresie: obraz oryginalny, sumę oryginału i wyniku filtracji oraz różnicę (bezwzględną) oryginału i wyniku filtracji.\n",
    " Uwaga. Aby uniknąć artefaktów, należy obraz wejściowy przekonwertować do formatu ze znakiem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_img_and_sum_and_mod(img, filtered):\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(24, 8)\n",
    "    ax[0].imshow(img, 'gray', vmin=0, vmax=256)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Obraz oryginalny\")\n",
    "\n",
    "    ax[1].imshow(img+filtered, 'gray')\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Suma obrazu i wyniku filtracji\")\n",
    "    \n",
    "    mod = np.abs(img - filtered)\n",
    "    ax[2].imshow(mod, 'gray', vmin=0, vmax=256)\n",
    "    ax[2].axis(\"off\")\n",
    "    ax[2].set_title(\"Moduł z różnicy\")\n",
    "\n",
    "disp_img_and_sum_and_mod(moon, moon_2)\n",
    "disp_img_and_sum_and_mod(moon, moon_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradienty (wykorzystanie pierwszej pochodnej obrazu)\n",
    "\n",
    "1. Wczytaj obraz _kw.png_. Stwórz odpowiednie maski opisane w kolejnych punktach i dokonaj filtracji.\n",
    "2. Wykorzystując gradient Robertsa przeprowadź detekcję krawędzi - poprzez wykonanie konwolucji obrazu z daną maską:\n",
    "\\begin{equation}\n",
    "R1 = \\begin{bmatrix} 0 & 0 & 0 \\\\ -1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}   \n",
    "R2 = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & -1 \\\\ 0 & 1 & 0 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Wykorzystaj stworzony wcześniej kod (przy laplasjanie) - dwie metody normalizacji oraz sposób wyświetlania.\n",
    "\n",
    "3. Analogicznie przeprowadź detekcję krawędzi za pomocą gradientu Prewitta (pionowy i poziomy)\n",
    "\\begin{equation}\n",
    "P1 = \\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1 \\end{bmatrix}   \n",
    "P2 = \\begin{bmatrix} -1 & -1 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 1 & 1 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "4. Podobnie skonstruowany jest gradient Sobela (występuje osiem masek, zaprezentowane są dwie ``prostopadłe''):\n",
    "\\begin{equation}\n",
    "S1 = \\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}   \n",
    "S2 = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Przeprowadź detekcję krawędzi za pomocą gradientu Sobela. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R1 = np.array([[0, 0, 0], [-1, 0, 0], [0, 1, 0]])\n",
    "R2 = np.array([[0, 0, 0], [0, 0, -1], [0, 1, 0]])\n",
    "P1 = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "P2 = P1.T\n",
    "S1 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "S2 = S1.T\n",
    "\n",
    "kw_1 = np.ones(shape = kw.shape, dtype=np.float32)\n",
    "cv2.filter2D(kw.astype(np.float32), -1, R1, dst = kw_1)\n",
    "kw_2 = kw_1 + 128\n",
    "kw_3 = np.abs(kw_1)\n",
    "\n",
    "kw_4 = np.ones(shape = kw.shape, dtype=np.float32)\n",
    "cv2.filter2D(kw.astype(np.float32), -1, R2, dst = kw_4)\n",
    "kw_5 = kw_4 + 128\n",
    "kw_6 = np.abs(kw_4)\n",
    "\n",
    "kw_7 = np.ones(shape = kw.shape, dtype=np.float32)\n",
    "cv2.filter2D(kw.astype(np.float32), -1, P1, dst = kw_7)\n",
    "kw_8 = kw_7 + 128\n",
    "kw_9 = np.abs(kw_7)\n",
    "\n",
    "kw_10 = np.ones(shape = kw.shape, dtype=np.float32)\n",
    "cv2.filter2D(kw.astype(np.float32), -1, P2, dst = kw_10)\n",
    "kw_11 = kw_10 + 128\n",
    "kw_12 = np.abs(kw_10)\n",
    "\n",
    "kw_13 = np.ones(shape = kw.shape, dtype=np.float32)\n",
    "cv2.filter2D(kw.astype(np.float32), -1, S1, dst = kw_13)\n",
    "kw_14 = kw_13 + 128\n",
    "kw_15 = np.abs(kw_13)\n",
    "\n",
    "kw_16 = np.ones(shape = kw.shape, dtype=np.float32)\n",
    "cv2.filter2D(kw.astype(np.float32), -1, S2, dst = kw_16)\n",
    "kw_17 = kw_16 + 128\n",
    "kw_18 = np.abs(kw_16)\n",
    "\n",
    "disp_img_and_filt_no0256(kw, kw_2)\n",
    "disp_img_and_filt_no0256(kw, kw_3)\n",
    "disp_img_and_filt_no0256(kw, kw_5)\n",
    "disp_img_and_filt_no0256(kw, kw_6)\n",
    "disp_img_and_filt_no0256(kw, kw_8)\n",
    "disp_img_and_filt_no0256(kw, kw_9)\n",
    "disp_img_and_filt_no0256(kw, kw_11)\n",
    "disp_img_and_filt_no0256(kw, kw_12)\n",
    "disp_img_and_filt_no0256(kw, kw_14)\n",
    "disp_img_and_filt_no0256(kw, kw_15)\n",
    "disp_img_and_filt_no0256(kw, kw_17)\n",
    "disp_img_and_filt_no0256(kw, kw_18)\n",
    "\n",
    "disp_img_and_sum_and_mod(kw, kw_2)\n",
    "disp_img_and_sum_and_mod(kw, kw_3)\n",
    "disp_img_and_sum_and_mod(kw, kw_5)\n",
    "disp_img_and_sum_and_mod(kw, kw_6)\n",
    "disp_img_and_sum_and_mod(kw, kw_8)\n",
    "disp_img_and_sum_and_mod(kw, kw_9)\n",
    "disp_img_and_sum_and_mod(kw, kw_11)\n",
    "disp_img_and_sum_and_mod(kw, kw_12)\n",
    "disp_img_and_sum_and_mod(kw, kw_14)\n",
    "disp_img_and_sum_and_mod(kw, kw_15)\n",
    "disp_img_and_sum_and_mod(kw, kw_17)\n",
    "disp_img_and_sum_and_mod(kw, kw_18)"
   ]
  },
  {
   "source": [
    "Różne maski dają różne efekty dotyczące lini pionowych, poziomych, bądź ukośnych."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Na podstawie dwóch ortogonalnych masek np. Sobela można stworzyć tzw. filtr kombinowany - pierwiastek kwadratowy z sumy kwadratów gradientów:\n",
    "\\begin{equation}\n",
    "OW = \\sqrt{(O * S1)^2 + (O * S2)^2}\n",
    "\\end{equation}\n",
    "gdzie:  $OW$ - obraz wyjściowy, $O$ - obraz oryginalny (wejściowy), $S1,S2$ - maski Sobela, $*$ - operacja konwolucji.\n",
    "\n",
    "Zaimplementuj filtr kombinowany.\n",
    "\n",
    "Uwaga. Proszę zwrócić uwagę na konieczność zmiany formatu danych obrazu wejściowego - na typ znakiem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(img):\n",
    "    global S1\n",
    "    global S2\n",
    "    conv1 = cv2.filter2D(img.astype(np.float32), -1, S1)\n",
    "    conv2 = cv2.filter2D(img.astype(np.float32), -1, S2)\n",
    "    out = np.sqrt(conv1**2 + conv2**2)\n",
    "    disp_img_and_sum_and_mod(img, out)\n",
    "\n",
    "comb(kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Istnieje alternatywna wersja filtra kombinowanego, która zamiast pierwiastka z sumy kwadratów wykorzystuje sumę modułów (prostsze obliczenia). \n",
    "Zaimplementuj tę wersję. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def comb2(img):\n",
    "    global S1\n",
    "    global S2\n",
    "    conv1 = cv2.filter2D(img.astype(np.float32), -1, S1)\n",
    "    conv2 = cv2.filter2D(img.astype(np.float32), -1, S2)\n",
    "    out = np.abs(conv1) + np.abs(conv2)\n",
    "    disp_img_and_sum_and_mod(img, out)\n",
    "\n",
    "comb2(kw)"
   ]
  },
  {
   "source": [
    "Krawiędzie pionowe i poziome są dużo ostrzejsze, natomiast wokół ukosnych można zaobserwować dodatkową \"ramkę\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Wczytaj plik _jet.png_ (zamiast _kw.png_).\n",
    "Sprawdź działanie obu wariantów filtracji kombinowanej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comb(jet)\n",
    "comb2(jet)"
   ]
  },
  {
   "source": [
    "Krawędzie często zostały zastąpione kolorem białym, co w niektórych przypadkach zaburzyło ich widoczność."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "name": "python383jvsc74a57bd0c468bac67d804d57f893e0f9ada055e3f07962baf7e8a6539193483b2e095161",
   "display_name": "Python 3.8.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}